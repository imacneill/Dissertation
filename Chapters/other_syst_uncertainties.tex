\chapter{Other Uncertainties Due to use of Simulations}
\section{Uncertainties  Involved in Event Generation}
\subsection{Uncertainties Due to Parton Distribution Functions}	
add brief description of pdfs...\\

The recommendations of the PDF4LHC ~\cite{PDF4LHC} group are followed for estimating the acceptance uncertainty from the pdf. The predictions from CT10, MSTW, and NNPDF sets are used. The LHAPDF package is used for pdfs and the re-weight function. Each set and all of it's error subsets are run over and used to re-weight the \ttZ \ MC to determine an acceptance. MC events are re-weighted from the generator pdf (CTEQ6) to the variation based on the parton type and momentum.\\

\subsubsection{CT10}
The PDF uncertainty for CT10 is calculated by\\
$\Delta A^{+} = \sqrt{ \displaystyle \sum \limits_{i=1}^N [	\max(A_i^{+} - A_0, A_i^{-} - A_0, 0) ] ^ 2}$ \\
$\Delta A^{-} = \sqrt{ \displaystyle \sum \limits_{i=1}^N [	\max(A_0 - A_i^{+}, A_0 - A_i^{-} , 0) ] ^ 2}$\\
where $A_0$ is computed with the central PDF, i runs over the error sets, $A^{+}$ and $A^{-}$ denote the up and down errors respectively on the acceptances of the ith eigenvector subset. The $\alpha _s$ uncertainty is obtained by considering PDFs for $\alpha _s$ = 0.116, 0.117, 0.118, 0.119, 0.120. The same equations above are applied to these subsets. Finally, it is noted that the PDFs for CT10 are at 90\% CL variations and thus the results are scaled down by 1.645 to obtain the 68\% CL uncertainty.
	
\subsubsection{MSTW}
5 different sets are used for MSTW with $\alpha _s = \alpha _s ^ 0$, $\alpha _s ^ 0 \pm 0.5 \sigma$, and $\alpha _s ^ 0 \pm \sigma$. The uncertainty is given with the following formula\\

$\Delta A^{+} = \underset{\alpha _s}{\max} [ A_{\alpha _ s} + \Delta A_{\alpha _s} ]  - A_0  $ \\
$\Delta A^{-} = A_0 -  \underset{\alpha _s}{\max} [ A_{\alpha _ s} - \Delta A_{\alpha _s} ] $ \\

%$\Delta A^{+} =  max _{\alpha _s} { A_{\alpha _ s} + \Delta A_{\alpha _s} } - A_0 $\\
%$\Delta A^{-} = A_0 -  max _{\alpha _s} { A_{\alpha _ s} - \Delta A_{\alpha _s} } $ \\
where $A_0$ is from the central value pdf.\\

\subsubsection{NNPDF2.0}
The NNPDF samples of PDF+$\alpha _s$ is obtained by using NNPDF sets with different fixed $\alpha _s$ corresponding to a Gaussian sample around the nominal $\alpha _s = 0.119$ as shown in Table~\ref{tab:nnpdfsets}.
 
\begin{table}[h]
\begin{center}
\caption{\small\label{tab:nnpdfsets} Number of NNPDF replicas for each $\alpha _s$.}
\begin{tabular}{c|ccccccc}\hline
$\alpha _s$         &  0.116 & 0.117 & 0.118 & 0.119 & 0.120 & 0.121 & 0.122 \\ \hline
$N_{rep}$                &  5         &  27      &  72      &   100   &  72     &   27    &    5       \\
\hline
\end{tabular}
\end{center}
\end{table}

The uncertainty is computed using the following equations,\\
$\Delta A ^{+} = \sqrt{  \frac{1}{N^{+} - 1} \sum \limits_{i=1}^{N^{+}} (A_i - A_0)^2}$,\\
$\Delta A ^{-} = \sqrt{  \frac{1}{N^{-} - 1} \sum \limits_{j=1}^{N^{-}} (A_0 - A_j)^2}$,\\

with $A_0$ computed front he central value PDF at $\alpha = 0.119$, i running over the $N^{+}$ replicas where $A_i$ \gt $A_0$, and j running over the $N^{-}$ replicas with $A_j$ \lt $A_0$.

\subsubsection{Combined Results}
To combine the measurements into one error, the uncertainty is computed as follows\\
$\Delta _{\max} = \underset{i}{\max}  [A_i + \Delta A^{+} _i]$\\
$\Delta _{\max} = \underset{i}{\min}  [A_i - \Delta A^{-} _i]$\\
and the PDF uncertainty is\\
$ Unc_{PDF} = \frac{1}{2}(\Delta _{max} - \Delta _{min} )$\\
where i runs over all of the PDF sets listed above.\\

Using this procedure, yields an uncertainty of 1.5\%.

\subsection{Uncertainties Due to Q$^2$ ... change name to english words}
add brief description of Q$^2$...\\

\subsection{Uncertainties Due to top mass}
add brief description of top mass...\\
Given that no \ttZ \ samples exist with scaled up or down top mass, or generator matching, or q$^2$ values, the \ttbar \ samples in Table ~\ref{tab:sampleupdown} with these variations were chosen and assumed to provide an accurate enough picture of uncertainty for these purposes.
\begin{table}[h]
\begin{center}
\caption{\small\label{tab:sampleupdown} List of alternate \ttbar \ samples scaling up or down relative parameters to the systematics. SU12 stands for ``Summer12\_DR53X-PU\_S10\_START53\_V7A-v1."}
\begin{tabular}{l}\hline
Sample   \\ \hline
 \verb=/TTJets_mass178_5_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=   \\
 \verb=/TTJets_mass166_5_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=   \\  %\hdashline
 \verb=/TTJets_scaleup_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=  \\
 \verb=/TTJets_scaledown_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=  \\ %\hdashline
 \verb=/TTJets_matchingup_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=  \\
 \verb=/TTJets_matchingdown_TuneZ2star_8TeV-madgraph-tauola/SU12/AODSIM=  \\
\hline
\end{tabular}
\end{center}
\end{table}

In order to use the \ttbar \ samples, the full analysis selections must be modified to become a mono-lepton selection instead of a tri-lepton selection, so that only prompt leptons are considered and the jet production methods remain the same. In essence this just removes the Z selection. There is an additional benefit from this modified selection in that it creates a high statistics region to derive the systematic errors. The number of events passing the modified selections in each sample are compared to the number of generator level events with 1 lepton. The \verb=/TTJets_SemiLeptMGDecays_8TeV-madgraph/Su12_V7A_ext-v1/AODSIM=  (where Su12 stands for ``Summer12\_DR53X-PU\_S10\_START53'') sample is used to produce a central value, and the fraction passing from the varied samples is compared to the fraction passing from the central value to determine the systematic error on each variation. The results are summarized in Table ~\ref{tab:systupdown}.

\begin{table}[h]
\begin{center}
\caption{\small\label{tab:systupdown} Summary of systematic b-Tag uncertainties split by light flavor and b contributions. Note: Half the error established by varying the top mass is used because the mass range is much wider than the current considered error on the top mass measurement.}
\begin{tabular}{lccc}\hline
Source                  &  N Pass / N Gen & \% Deviation from Central & Notes\\ \hline
Central                 & 0.265 & & \\
Q$^2$ Up                 & 0.261 & -1.5\% & \\
Q$^2$ Down           & 0.270 & 1.8\% & \\
Matching Up       & 0.261 & -1.6\% & \\
Matching Down  & 0.267 & 0.8\% & \\
Mass 166.5         & 0.251 & -5.2\% & Use half \\
Mass 178.5         & 0.277 & 4.5\% & Use half \\
\hline
Total                     &             & 3.3\% & Used half of Mass variation \\
\hline
\end{tabular}
\end{center}
\end{table}


\subsection{Uncertainties Due to Generator}	
add brief description of generators...\\

The MC samples used in this analysis are primarily generated with the Madgraph event generator. Madgraph produces events at Leading Order. This may lead to a change in acceptance of the events compared to an NLO or NNLO event generator which comes into play with the signal acceptance. Despite the general belief that NLO samples are more accurate, Madgraph samples were still chosen here due to the inconsistent widespread availability of aMC@NLO samples as well as the fact that the available \ttZ \ and \ttW \ aMC@NLO were produced without final state photon radiation. To study this potential uncertainty, 2 \ttZ samples are used and are summarized in table ~\ref{tab:ttZGeneratorMCs}. The first is a Madgraph ~\cite{Alwall:2011uj} sample which is used elsewhere in the analysis. The second is an aMC@NLO (~\cite{Frederix:2011zi, Frederix:2011ss} based on the MC@NLO formalism \cite{Frixione:2002ik} and the MadGraph5 framework \cite{Alwall:2011uj}) sample. \\








For each sample an efficiency ($\epsilon$) is prepared. The efficiency defined as\\
$\epsilon = \frac{n\ with\ 3\ leptons\ and\ 4\ jets}{n\ with\ 3\ leptons}$\\

The exact selections for the denominator are:
\begin{itemize}
\item Exactly 3 status 3 generator leptons (electrons or muons)
\item All of the above generator leptons with \pt \gt 20 \GeV and \aeta \lt 2.4.
\item All of the above generator leptons came from a W or a Z.
\item Exactly 3 reconstructed leptons (electrons or muons) that pass the identification and isolation selections in Section~\ref{sec:eventsel}
\item Reconstructed leptons that do not match the generator leptons above are rejected.
\end{itemize}

The exact selections for the numerator are:
\begin{itemize}
\item Denominator as above.
\item At least 4 pfJets with applicable energy corrections with \pt \gt 20 \GeV and \aeta \lt 2.4. 
\item Jets within a cone 0.5 of a lepton identified in the numerator are rejected.
\item Jets with \lt 10\% of their energy coming from the primary vertex are rejected.
\end{itemize}

Then the difference is defined as\\
$\Delta = | 1 - \frac{\epsilon _{aMC@NLO}}{\epsilon _{Madgraph}} |$
and the results are summarize in table ~\ref{tab:systgeneratorsum}

\begin{table}[h]
\begin{center}
\caption{\small\label{tab:systgeneratorsum} Summary of the efficiencies of jet selection in Madgraph and aMC@NLO.}
\begin{tabular}{ccc}\hline
Madgraph           &  aMC@NLO & Difference \\ \hline
0.38                      & 0.36              & 5\%\\
\hline
\end{tabular}
\end{center}
\end{table}

After evaluating and comparing the efficiencies, The contribution to the signal uncertainty from the generator calculation order is set at 5\%.

\section{Jet Energy Scale and Resolution}
add brief description of jes and her...\\

jes\\
The jet energies have been corrected in data with a residual correction factor to account for differences between measured jet energies in data and in Monte Carlo~\cite{jes_ref}. These corrections come with uncertainties and thus matter for the signal acceptance. To account for this, we vary the jet transverse momenta up and down by the 1 standard deviation uncertainties and compare the change in predicted yields in MC. The resultant uncertainty is 4.8\% and is listed in Table ~\ref{tab:systSumm}.\\

jer\\
The recommended prescription for determining uncertainty on the energy resolution of particle flow jets is outlined in ~\cite{jer_ref}. Using signal Monte Carlo, the prescription was applied as follows:
\begin{itemize}
\item each reconstructed jet is matched to the closest generator jet within a cone of $\Delta R < 0.5$
\item if a match is found the transverse momentum of the reconstructed jet is scaled by \\
$\pt \rightarrow max[0, \pt ^{gen} + c \times (\pt - \pt ^{gen})]$ \\
where $\pt ^{gen}$ is the transverse momentum of the matched generator jet, and c is the data/MC scale factor between the measured and expected particle flow jet resolution in Table ~\ref{tab:jer_scalefactor}.
\item if no match is found a gaussian centered at unit and with a width of $c$ is used to smear the momentum instead
\end{itemize}

\begin{table}[h]
\begin{center}
\caption{\small \label{tab:jer_scalefactor} data/MC scale factors used in determining the Jet Energy Resolution.}
\begin{tabular}{c|c}\hline
Jet Pseudorapidity & Scale Factor \\ \hline \hline
0.0 - 0.5 & 1.052 \\
0.5 - 1.1 & 1.057 \\
1.1 - 1.7 & 1.096 \\
1.7 - 2.3 & 1.134 \\
2.3 - 5.0 & 1.288 \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

To determine the systematic uncertainty on this procedure, up and down variations (Table ~\ref{tab:jer_scalefactor_updown}) on the scale factor c are used. The yields in \ttZ \ signal MC are determined with the central value of c as well as the up and down values. The uncertainty is given by\\
uncertainty $= | \frac{Yield _{up} - Yield _{down}}{Yield _{central}} | $

\begin{table}[h]
\begin{center}
\caption{\small \label{tab:jer_scalefactor_updown} data/MC up/down scale factors used in determining the systematic uncertainty on Jet Energy Resolution.}
\begin{tabular}{c|c|c}\hline
Jet Pseudorapidity & Scale Factor (UP) & Scale Factor (DOWN)\\ \hline \hline
0.0 - 0.5 & 1.115 & 0.990 \\
0.5 - 1.1 & 1.114 & 1.001 \\
1.1 - 1.7 & 1.161 & 1.032 \\
1.7 - 2.3 & 1.228 & 1.042 \\
2.3 - 5.0 & 1.488 & 1.089 \\
\hline
\hline
\end{tabular}
\end{center}
\end{table}

After following this procedure, the acceptance systematic due to Jet Energy Resolution is found to be 0.4\%. This result is summarized in Table ~\ref{tab:systSumm}.\\

\section{Pile Up}
In the LHC, large bunches of protons collide at a rapid rate. The rate of bunch crossings can theoretically be pushed to near the threshold of timing for the machines electronics which can lead to residual energy still being measured in the detector from a previous collision during the current collision. This is called ``out of time pile up'' and is not an issue at the current rate of collisions for the LHC. Another form of pile up, known as ``in time pile up'' is an issue and is caused multiple protons colliding within the crossing bunches.\\ 

Proton collisions are frequent, but collisions that produce interesting outcomes are not. So the LHC allows many collisions to happen at once in hopes that one will be interesting. In time pile up occurs when one proton collision produces an outcome that physicists would like to study, but at the same time other collisions produce uninteresting outcomes that never-the-less add energy into the detector which may alter the appearance of the decay products of the collision that physicists want to investigate.\\

Several techniques are employed to mitigate this affect in the jet clustering algorithms, jet energy measurements, and the lepton energy measurements with most of the techniques reducing to some level of subtracting an average ambient energy which has been measured in minimum bias events. However, this still produces some level of uncertainty in the current measurements, and can matter for event acceptance (for example when determining the amount of energy in a cone around a lepton for an isolation measurement).\\

To evaluate this level of uncertainty, Monte Carlo samples are compared to data in the selection region. The number of vertices in the events are measured, and the Monte Carlo events are reweighed to have the same distribution of vertices as the data events. From here total cross section of minimum bias events is varied up and down by 5\% when reweighing the Monte Carlo samples. The effect on the signal yield is found to be $\pm 5\%$ after full selections.